Pass a pointer to the AGENT_DATA and PARAMS to the routines that run on host and device.

Only keep track of a subset of the theta values with lambda values.

Write position, angle, and action to a file for playback.


Change test to do restarts?


-------
Sharing
-------
Average the theta values across all agents
(done)	Straight average, all agents given the same weight
			Exclude values that have never been updated
			Give extra weight to agents that 'own' a section of the state space.
		Keep track of the 'update weight' which is the sum of the lambda amounts used to update each theta, and when sharing use a weighted average based on the 'update weights' 
	
record all state, action, result, state action values for the episode, then have all agents update their parameters by using the same


---------------
Differentiation
---------------
Partition the state space - each agent starts in their sector of state space whenever their state is randomized.

Use different re-start intervals

Assign a wider range for initial states

